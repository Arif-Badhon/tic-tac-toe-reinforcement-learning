{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook will discuss the reinfrocement learning for ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class state:\n",
    "    def __init__(self, p1, p2):\n",
    "        self.board = np.zeros((BOARD_ROWS, BOARD_COLS))\n",
    "        self.p1 = p1\n",
    "        self.p2 = p2\n",
    "        self.isEnd = False\n",
    "        self.boardHash = None\n",
    "        #init player 1 first\n",
    "        self.playerSymbol = 1\n",
    "\n",
    "    \n",
    "    #get unique hash of current board status\n",
    "    def getHash(self):\n",
    "        self.boardHash = str(self.board.reshape(BOARD_COLS*BOARD_ROWS))\n",
    "        return self.boardHash\n",
    "    \n",
    "    def winner(self):\n",
    "        # row\n",
    "        for i in range(BOARD_ROWS):\n",
    "            if sum(self.board[i,:]) == 3:\n",
    "                self.isEnd = True\n",
    "                return 1\n",
    "            if sum(self.board[i, :] == -3):\n",
    "                self.isEnd = True\n",
    "                return -1\n",
    "        \n",
    "        #col\n",
    "        for i in range(BOARD_COLS):\n",
    "            if sum(self.board[:, i]) == 3:\n",
    "                self.isEnd = True\n",
    "                return 1\n",
    "            if sum(self.board[:, i]) == -3:\n",
    "                self.isEnd = True\n",
    "                return -1\n",
    "        \n",
    "        #diagonal\n",
    "        diag_sum1 = sum([self.board[i,i] for i in range(BOARD_COLS)])\n",
    "        diag_sum2 = sum([self.board[i, BOARD_COLS-i-1] for i in range(BOARD_COLS)])\n",
    "        diag_sum = max(diag_sum1, diag_sum2)\n",
    "        if diag_sum == 3:\n",
    "            self.isEnd = True\n",
    "            return 1\n",
    "        if diag_sum == -3:\n",
    "            self.isEnd = True\n",
    "            return -1\n",
    "        \n",
    "        #tie\n",
    "        # no available positions\n",
    "        if len(self.availablePositions()) == 0:\n",
    "            self.isEnd = True\n",
    "            return 0\n",
    "        #not end\n",
    "        self.isEnd = False\n",
    "        return None\n",
    "    \n",
    "    \n",
    "    def availablePositions(self):\n",
    "        positions = []\n",
    "        for i in range(BOARD_ROWS):\n",
    "            for j in range(BOARD_COLS):\n",
    "                if self.board[i, j] == 0:\n",
    "                    positions.append((i, j)) #need to be tuple  \n",
    "        return positions\n",
    "    \n",
    "    def updateState(self, position):\n",
    "        self.board[position] = self.playerSymbol\n",
    "        #switch to another player\n",
    "        self.playerSymbol = -1 if self.playerSymbol == 1 else 1\n",
    "\n",
    "\n",
    "    # only when game ends\n",
    "    def giveReward(self):\n",
    "        result = self.winner()\n",
    "        #backpropagate reward\n",
    "        if result == 1:\n",
    "            self.p1.feedReward(1)\n",
    "            self.p2.feedReward(0)\n",
    "        elif result == -1:\n",
    "            self.p1.feedReward(0)\n",
    "            self.p2.feedReward(1)\n",
    "        else:\n",
    "            self.p1.feedReward(0.5)\n",
    "            self.p2.feedReward(0.5)\n",
    "\n",
    "\n",
    "    #board reset\n",
    "    def reset(self):\n",
    "        self.board = np.zeros((BOARD_ROWS, BOARD_COLS))\n",
    "        self.boardHash = None\n",
    "        self.isEnd = False\n",
    "        self.playerSymbol = 1\n",
    "\n",
    "    \n",
    "    def play(self, rounds=100):\n",
    "        for i in range (rounds):\n",
    "            if i%1000 == 0:\n",
    "                print(\"Rounds {}\".format(i))\n",
    "            while not self.isEnd:\n",
    "                #player j\n",
    "                positions = self.availablePositions()\n",
    "                p1_action = self.p1.chooseAction(positions, self.board, self.playerSymbol)\n",
    "                # take action and update board state\n",
    "                self.updateState(p1_action)\n",
    "                board_hash = self.getHash()\n",
    "                self.p1.addState(board_hash)\n",
    "                # check board status if it is end\n",
    "\n",
    "                win = self.winner()\n",
    "                if win is not None:\n",
    "                    # self.showBoard()\n",
    "                    # ended with p1 either win or draw\n",
    "                    self.giveReward()\n",
    "                    self.p1.reset()\n",
    "                    self.p2.reset()\n",
    "                    self.reset()\n",
    "                    break\n",
    "\n",
    "                else:\n",
    "                    #player 2\n",
    "                    positions = self.availablePositions()\n",
    "                    p2_action = self.p2.chooseAction(positions, self.board, self.playerSymbol)\n",
    "                    self.updateState(p2_action)\n",
    "                    board_hash = self.getHash()\n",
    "                    self.p2.addState(board_hash)\n",
    "\n",
    "                    win = self.winner()\n",
    "                    if win is not None:\n",
    "                        # self.showBoard()\n",
    "                        # ended with p2 either win or draw\n",
    "                        self.giveReward()\n",
    "                        self.p1.reset()\n",
    "                        self.p2.reset()\n",
    "                        self.reset()\n",
    "                        break\n",
    "\n",
    "\n",
    "    #play with human\n",
    "    def play2(self):\n",
    "        while not self.isEnd:\n",
    "            # player 1\n",
    "            positions = self.availablePositions()\n",
    "            p1_action = self.p1.chooseAction(positions, self.board, self.playerSymbol)\n",
    "            #take action and update board state\n",
    "            self.updateState(p1_action)\n",
    "            self.showBoard()\n",
    "            #check the board status to see if it is end\n",
    "            win = self.winner()\n",
    "            if win is not None:\n",
    "                if win == 1:\n",
    "                    print(self.p1.name, \"wins!\")\n",
    "                else:\n",
    "                    print(\"tie!\")\n",
    "                self.reset()\n",
    "                break\n",
    "            else:\n",
    "                #player 2\n",
    "                positions = self.availablePositions()\n",
    "                p2_action = self.p2.chooseAction(positions)\n",
    "\n",
    "                self.updateState(p2_action)\n",
    "                self.showBoard()\n",
    "                win = self.winner()\n",
    "                if win is not None:\n",
    "                    if win == -1:\n",
    "                        print(self.p2.name, \"wins!\")\n",
    "                    else:\n",
    "                        print(\"tie!\")\n",
    "                    self.reset()\n",
    "                    break\n",
    "\n",
    "\n",
    "    def showBoard(self):\n",
    "        #p1: x p2: o\n",
    "        for i in range(0, BOARD_ROWS):\n",
    "            print('................................')\n",
    "            out = ' | '\n",
    "            for j in range(0, BOARD_COLS):\n",
    "                if self.board[i, j] == 1:\n",
    "                    token = 'x'\n",
    "                if self.board[i, j] == -1:\n",
    "                    token = 'o'\n",
    "                if self.board[i, j] == 0:\n",
    "                    token = ' '\n",
    "                out += token + ' | '\n",
    "            print(out)\n",
    "        print('...................') \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class player:\n",
    "    def __init__(self, name, exp_rate=0.3):\n",
    "        self.name = name\n",
    "        self.states = []\n",
    "        self.lr = 0.2\n",
    "        self.exp_rate = exp_rate\n",
    "        self.decay_gamma = 0.9\n",
    "        self.states_value = {} # state --> value\n",
    "\n",
    "\n",
    "    def getHash(self, board):\n",
    "        boardHash = str(board.reshape(BOARD_COLS*BOARD_ROWS))\n",
    "        return boardHash\n",
    "    \n",
    "    def chooseAction(self, positions, current_board, symbol):\n",
    "        if np.random.uniform(0, 1) <= self.exp_rate:\n",
    "            #take random action\n",
    "            idx = np.random.choice(len(positions))\n",
    "            action = positions[idx]\n",
    "        else:\n",
    "            value_max = -999\n",
    "            for p in positions:\n",
    "                next_board = current_board.copy()\n",
    "                next_board[p] = symbol\n",
    "                next_boardHash = self.getHash(next_board) \n",
    "                value = 0 if self.states_value.get(next_boardHash) is None else self.states_value.get(next_boardHash)\n",
    "                if value >= value_max:\n",
    "                    value_max = value\n",
    "                    action = p\n",
    "\n",
    "        return action\n",
    "    \n",
    "    # at the end of game, backpropagate and update states value\n",
    "    def feedReward(self, reward):\n",
    "        for st in reversed(self.states):\n",
    "            if self.states_value.get(st) is None:\n",
    "                self.states_value[st] = 0\n",
    "            self.states_value[st] += self.lr*(self.decay_gamma*reward - self.states_value[st])\n",
    "            reward = self.states_value[st]\n",
    "\n",
    "    def addState(self, state):\n",
    "        pass \n",
    "\n",
    "\n",
    "    def reset(self):\n",
    "        self.states = []\n",
    "\n",
    "    def savePolicy(self):\n",
    "        fw = open('policy_'+str(self.name), 'wb')\n",
    "        pickle.dump(self.states_value, fw)\n",
    "        fw.close()\n",
    "\n",
    "    def loadPolicy(self, file):\n",
    "        fr = open(file, 'rb')\n",
    "        self.states_value = pickle.load(fr)\n",
    "        fr.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Human player\n",
    "class HumanPlayer:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "\n",
    "    def chooseAction(self, positions):\n",
    "        while True:\n",
    "            row = int(input(\"input your action row:\"))\n",
    "            col = int(input(\"input your action col\"))\n",
    "            action = (row, col)\n",
    "            if action in positions:\n",
    "                return action\n",
    "            \n",
    "    #append a hash state\n",
    "    def addState(self, state):\n",
    "        pass\n",
    "\n",
    "    #at the end of game, backpropagate and update status value\n",
    "    def feedReward(self, reward):\n",
    "        pass\n",
    "\n",
    "    def reset(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Rounds 0\n"
     ]
    }
   ],
   "source": [
    "BOARD_ROWS = 3\n",
    "BOARD_COLS = 3\n",
    "\n",
    "p1 = player(\"p1\")\n",
    "p2 = player(\"p2\")\n",
    "\n",
    "\n",
    "st = state(p1, p2)\n",
    "print(\"Training...\")\n",
    "st.play(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1.savePolicy()\n",
    "p2.savePolicy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "................................\n",
      " |   |   |   | \n",
      "................................\n",
      " |   |   |   | \n",
      "................................\n",
      " |   |   | x | \n",
      "...................\n",
      "................................\n",
      " |   |   | o | \n",
      "................................\n",
      " |   |   |   | \n",
      "................................\n",
      " |   |   | x | \n",
      "...................\n",
      "................................\n",
      " |   |   | o | \n",
      "................................\n",
      " |   |   |   | \n",
      "................................\n",
      " |   | x | x | \n",
      "...................\n",
      "................................\n",
      " |   |   | o | \n",
      "................................\n",
      " |   |   |   | \n",
      "................................\n",
      " | o | x | x | \n",
      "...................\n",
      "................................\n",
      " |   |   | o | \n",
      "................................\n",
      " |   |   | x | \n",
      "................................\n",
      " | o | x | x | \n",
      "...................\n",
      "................................\n",
      " |   |   | o | \n",
      "................................\n",
      " |   | o | x | \n",
      "................................\n",
      " | o | x | x | \n",
      "...................\n",
      "................................\n",
      " |   |   | o | \n",
      "................................\n",
      " | x | o | x | \n",
      "................................\n",
      " | o | x | x | \n",
      "...................\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m p2 \u001b[38;5;241m=\u001b[39m HumanPlayer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m st \u001b[38;5;241m=\u001b[39m state(p1, p2)\n\u001b[0;32m----> 8\u001b[0m \u001b[43mst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplay2\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[15], line 158\u001b[0m, in \u001b[0;36mstate.play2\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;66;03m#player 2\u001b[39;00m\n\u001b[1;32m    157\u001b[0m     positions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavailablePositions()\n\u001b[0;32m--> 158\u001b[0m     p2_action \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchooseAction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpositions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdateState(p2_action)\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshowBoard()\n",
      "Cell \u001b[0;32mIn[17], line 8\u001b[0m, in \u001b[0;36mHumanPlayer.chooseAction\u001b[0;34m(self, positions)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mchooseAction\u001b[39m(\u001b[38;5;28mself\u001b[39m, positions):\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m----> 8\u001b[0m         row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput your action row:\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m         col \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput your action col\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     10\u001b[0m         action \u001b[38;5;241m=\u001b[39m (row, col)\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: ''"
     ]
    }
   ],
   "source": [
    "p1 = player(\"computer\", exp_rate=0)\n",
    "p1.loadPolicy(\"policy_p1\")\n",
    "\n",
    "p2 = HumanPlayer(\"human\")\n",
    "\n",
    "\n",
    "st = state(p1, p2)\n",
    "st.play2()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
